<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - 40aa2bc153a0d1b02abb53793fdd4d7c819227e9 - src/include/panoc-alm/inner/detail/panoc-helpers.hpp</title>
  <link rel="stylesheet" type="text/css" href="../../../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../../../index.html">top level</a> - <a href="index.html">src/include/panoc-alm/inner/detail</a> - panoc-helpers.hpp<span style="font-size: 80%;"> (source / <a href="panoc-helpers.hpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">40aa2bc153a0d1b02abb53793fdd4d7c819227e9</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">49</td>
            <td class="headerCovTableEntry">49</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2021-04-04 18:38:31</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntry">8</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../../../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : #pragma once</a>
<a name="2"><span class="lineNum">       2 </span>            : </a>
<a name="3"><span class="lineNum">       3 </span>            : #include &lt;panoc-alm/util/problem.hpp&gt;</a>
<a name="4"><span class="lineNum">       4 </span>            : </a>
<a name="5"><span class="lineNum">       5 </span>            : namespace pa::detail {</a>
<a name="6"><span class="lineNum">       6 </span>            : </a>
<a name="7"><span class="lineNum">       7 </span>            : /// Calculate both ψ(x) and the vector ŷ that can later be used to compute ∇ψ.</a>
<a name="8"><span class="lineNum">       8 </span>            : /// @f[ \psi(x^k) = f(x^k) + \frac{1}{2}</a>
<a name="9"><span class="lineNum">       9 </span>            : /// \text{dist}_\Sigma^2\left(g(x^k) + \Sigma^{-1}y,\;D\right) @f]</a>
<a name="10"><span class="lineNum">      10 </span>            : /// @f[ \hat{y}  @f]</a>
<a name="11"><span class="lineNum">      11 </span><span class="lineCov">       2166 : inline real_t calc_ψ_ŷ(const Problem &amp;p, ///&lt; [in]  Problem description</span></a>
<a name="12"><span class="lineNum">      12 </span>            :                        const vec &amp;x,     ///&lt; [in]  Decision variable @f$ x @f$</a>
<a name="13"><span class="lineNum">      13 </span>            :                        const vec &amp;y, ///&lt; [in]  Lagrange multipliers @f$ y @f$</a>
<a name="14"><span class="lineNum">      14 </span>            :                        const vec &amp;Σ, ///&lt; [in]  Penalty weights @f$ \Sigma @f$</a>
<a name="15"><span class="lineNum">      15 </span>            :                        vec &amp;ŷ        ///&lt; [out] @f$ \hat{y} @f$</a>
<a name="16"><span class="lineNum">      16 </span>            : ) {</a>
<a name="17"><span class="lineNum">      17 </span>            :     // g(x)</a>
<a name="18"><span class="lineNum">      18 </span><span class="lineCov">       2166 :     p.g(x, ŷ);</span></a>
<a name="19"><span class="lineNum">      19 </span>            :     // ζ = g(x) + Σ⁻¹y</a>
<a name="20"><span class="lineNum">      20 </span><span class="lineCov">       2166 :     ŷ += Σ.asDiagonal().inverse() * y;</span></a>
<a name="21"><span class="lineNum">      21 </span>            :     // d = ζ - Π(ζ, D)</a>
<a name="22"><span class="lineNum">      22 </span><span class="lineCov">       2166 :     ŷ = projecting_difference(ŷ, p.D);</span></a>
<a name="23"><span class="lineNum">      23 </span>            :     // dᵀŷ, ŷ = Σ d</a>
<a name="24"><span class="lineNum">      24 </span><span class="lineCov">       2166 :     real_t dᵀŷ = 0;</span></a>
<a name="25"><span class="lineNum">      25 </span><span class="lineCov">      11057 :     for (unsigned i = 0; i &lt; p.m; ++i) {</span></a>
<a name="26"><span class="lineNum">      26 </span><span class="lineCov">       8891 :         dᵀŷ += ŷ(i) * Σ(i) * ŷ(i); // TODO: vectorize</span></a>
<a name="27"><span class="lineNum">      27 </span><span class="lineCov">       8891 :         ŷ(i) = Σ(i) * ŷ(i);</span></a>
<a name="28"><span class="lineNum">      28 </span><span class="lineCov">       8891 :     }</span></a>
<a name="29"><span class="lineNum">      29 </span>            :     // ψ(x) = f(x) + ½ dᵀŷ</a>
<a name="30"><span class="lineNum">      30 </span><span class="lineCov">       2166 :     real_t ψ = p.f(x) + 0.5 * dᵀŷ;</span></a>
<a name="31"><span class="lineNum">      31 </span>            : </a>
<a name="32"><span class="lineNum">      32 </span><span class="lineCov">       4332 :     return ψ;</span></a>
<a name="33"><span class="lineNum">      33 </span><span class="lineCov">       2166 : }</span></a>
<a name="34"><span class="lineNum">      34 </span>            : </a>
<a name="35"><span class="lineNum">      35 </span>            : /// Calculate ∇ψ(x) using ŷ.</a>
<a name="36"><span class="lineNum">      36 </span>            : inline void</a>
<a name="37"><span class="lineNum">      37 </span><span class="lineCov">       1720 : calc_grad_ψ_from_ŷ(const Problem &amp;p, ///&lt; [in]  Problem description</span></a>
<a name="38"><span class="lineNum">      38 </span>            :                    const vec &amp;x,     ///&lt; [in]  Decision variable @f$ x @f$</a>
<a name="39"><span class="lineNum">      39 </span>            :                    const vec &amp;ŷ,     ///&lt; [in]  @f$ \hat{y} @f$</a>
<a name="40"><span class="lineNum">      40 </span>            :                    vec &amp;grad_ψ,      ///&lt; [out] @f$ \nabla \psi(x) @f$</a>
<a name="41"><span class="lineNum">      41 </span>            :                    vec &amp;work_n       ///&lt;       Dimension n</a>
<a name="42"><span class="lineNum">      42 </span>            : ) {</a>
<a name="43"><span class="lineNum">      43 </span>            :     // ∇ψ = ∇f(x) + ∇g(x) ŷ</a>
<a name="44"><span class="lineNum">      44 </span><span class="lineCov">       1720 :     p.grad_f(x, grad_ψ);</span></a>
<a name="45"><span class="lineNum">      45 </span><span class="lineCov">       1720 :     p.grad_g(x, ŷ, work_n);</span></a>
<a name="46"><span class="lineNum">      46 </span><span class="lineCov">       1720 :     grad_ψ += work_n;</span></a>
<a name="47"><span class="lineNum">      47 </span><span class="lineCov">       1720 : }</span></a>
<a name="48"><span class="lineNum">      48 </span>            : </a>
<a name="49"><span class="lineNum">      49 </span>            : /// Calculate both ψ(x) and its gradient ∇ψ(x).</a>
<a name="50"><span class="lineNum">      50 </span>            : /// @f[ \psi(x^k) = f(x^k) + \frac{1}{2}</a>
<a name="51"><span class="lineNum">      51 </span>            : /// \text{dist}_\Sigma^2\left(g(x^k) + \Sigma^{-1}y,\;D\right) @f]</a>
<a name="52"><span class="lineNum">      52 </span>            : /// @f[ \nabla \psi(x) = \nabla f(x) + \nabla g(x)\ \hat{y}(x) @f]</a>
<a name="53"><span class="lineNum">      53 </span>            : inline real_t</a>
<a name="54"><span class="lineNum">      54 </span><span class="lineCov">       1023 : calc_ψ_grad_ψ(const Problem &amp;p, ///&lt; [in]  Problem description</span></a>
<a name="55"><span class="lineNum">      55 </span>            :               const vec &amp;x,     ///&lt; [in]  Decision variable @f$ x @f$</a>
<a name="56"><span class="lineNum">      56 </span>            :               const vec &amp;y,     ///&lt; [in]  Lagrange multipliers @f$ y @f$</a>
<a name="57"><span class="lineNum">      57 </span>            :               const vec &amp;Σ,     ///&lt; [in]  Penalty weights @f$ \Sigma @f$</a>
<a name="58"><span class="lineNum">      58 </span>            :               vec &amp;grad_ψ,      ///&lt; [out] @f$ \nabla \psi(x) @f$</a>
<a name="59"><span class="lineNum">      59 </span>            :               vec &amp;work_n,      ///&lt;       Dimension n</a>
<a name="60"><span class="lineNum">      60 </span>            :               vec &amp;work_m       ///&lt;       Dimension m</a>
<a name="61"><span class="lineNum">      61 </span>            : ) {</a>
<a name="62"><span class="lineNum">      62 </span>            :     // ψ(x) = f(x) + ½ dᵀŷ</a>
<a name="63"><span class="lineNum">      63 </span><span class="lineCov">       1023 :     real_t ψ = calc_ψ_ŷ(p, x, y, Σ, work_m);</span></a>
<a name="64"><span class="lineNum">      64 </span>            :     // ∇ψ = ∇f(x) + ∇g(x) ŷ</a>
<a name="65"><span class="lineNum">      65 </span><span class="lineCov">       1023 :     calc_grad_ψ_from_ŷ(p, x, work_m, grad_ψ, work_n);</span></a>
<a name="66"><span class="lineNum">      66 </span><span class="lineCov">       2046 :     return ψ;</span></a>
<a name="67"><span class="lineNum">      67 </span><span class="lineCov">       1023 : }</span></a>
<a name="68"><span class="lineNum">      68 </span>            : </a>
<a name="69"><span class="lineNum">      69 </span>            : /// Calculate the gradient ∇ψ(x).</a>
<a name="70"><span class="lineNum">      70 </span>            : /// @f[ \nabla \psi(x) = \nabla f(x) + \nabla g(x)\ \hat{y}(x) @f]</a>
<a name="71"><span class="lineNum">      71 </span><span class="lineCov">         24 : inline void calc_grad_ψ(const Problem &amp;p, ///&lt; [in]  Problem description</span></a>
<a name="72"><span class="lineNum">      72 </span>            :                         const vec &amp;x,     ///&lt; [in]  Decision variable @f$ x @f$</a>
<a name="73"><span class="lineNum">      73 </span>            :                         const vec &amp;y, ///&lt; [in]  Lagrange multipliers @f$ y @f$</a>
<a name="74"><span class="lineNum">      74 </span>            :                         const vec &amp;Σ, ///&lt; [in]  Penalty weights @f$ \Sigma @f$</a>
<a name="75"><span class="lineNum">      75 </span>            :                         vec &amp;grad_ψ,  ///&lt; [out] @f$ \nabla \psi(x) @f$</a>
<a name="76"><span class="lineNum">      76 </span>            :                         vec &amp;work_n,  ///&lt;       Dimension n</a>
<a name="77"><span class="lineNum">      77 </span>            :                         vec &amp;work_m   ///&lt;       Dimension m</a>
<a name="78"><span class="lineNum">      78 </span>            : ) {</a>
<a name="79"><span class="lineNum">      79 </span>            :     // g(x)</a>
<a name="80"><span class="lineNum">      80 </span><span class="lineCov">         24 :     p.g(x, work_m);</span></a>
<a name="81"><span class="lineNum">      81 </span>            :     // ζ = g(x) + Σ⁻¹y</a>
<a name="82"><span class="lineNum">      82 </span><span class="lineCov">         24 :     work_m += (y.array() / Σ.array()).matrix();</span></a>
<a name="83"><span class="lineNum">      83 </span>            :     // d = ζ - Π(ζ, D)</a>
<a name="84"><span class="lineNum">      84 </span><span class="lineCov">         24 :     work_m = projecting_difference(work_m, p.D);</span></a>
<a name="85"><span class="lineNum">      85 </span>            :     // ŷ = Σ d</a>
<a name="86"><span class="lineNum">      86 </span><span class="lineCov">         24 :     work_m = Σ.asDiagonal() * work_m;</span></a>
<a name="87"><span class="lineNum">      87 </span>            : </a>
<a name="88"><span class="lineNum">      88 </span>            :     // ∇ψ = ∇f(x) + ∇g(x) ŷ</a>
<a name="89"><span class="lineNum">      89 </span><span class="lineCov">         24 :     p.grad_f(x, grad_ψ);</span></a>
<a name="90"><span class="lineNum">      90 </span><span class="lineCov">         24 :     p.grad_g(x, work_m, work_n);</span></a>
<a name="91"><span class="lineNum">      91 </span><span class="lineCov">         24 :     grad_ψ += work_n;</span></a>
<a name="92"><span class="lineNum">      92 </span><span class="lineCov">         24 : }</span></a>
<a name="93"><span class="lineNum">      93 </span>            : </a>
<a name="94"><span class="lineNum">      94 </span>            : /// Calculate the error between ẑ and g(x).</a>
<a name="95"><span class="lineNum">      95 </span>            : /// @f[ \hat{z}^k = \Pi_D\left(g(x^k) + \Sigma^{-1}y\right) @f]</a>
<a name="96"><span class="lineNum">      96 </span>            : inline void</a>
<a name="97"><span class="lineNum">      97 </span><span class="lineCov">         24 : calc_err_z(const Problem &amp;p, ///&lt; [in]  Problem description</span></a>
<a name="98"><span class="lineNum">      98 </span>            :            const vec &amp;x̂,     ///&lt; [in]  Decision variable @f$ \hat{x} @f$</a>
<a name="99"><span class="lineNum">      99 </span>            :            const vec &amp;y,     ///&lt; [in]  Lagrange multipliers @f$ y @f$</a>
<a name="100"><span class="lineNum">     100 </span>            :            const vec &amp;Σ,     ///&lt; [in]  Penalty weights @f$ \Sigma @f$</a>
<a name="101"><span class="lineNum">     101 </span>            :            vec &amp;err_z        ///&lt; [out] @f$ g(\hat{x}) - \hat{z} @f$</a>
<a name="102"><span class="lineNum">     102 </span>            : ) {</a>
<a name="103"><span class="lineNum">     103 </span>            :     // g(x̂)</a>
<a name="104"><span class="lineNum">     104 </span><span class="lineCov">         24 :     p.g(x̂, err_z);</span></a>
<a name="105"><span class="lineNum">     105 </span>            :     // ζ = g(x̂) + Σ⁻¹y</a>
<a name="106"><span class="lineNum">     106 </span>            :     // ẑ = Π(ζ, D)</a>
<a name="107"><span class="lineNum">     107 </span>            :     // g(x) - ẑ</a>
<a name="108"><span class="lineNum">     108 </span><span class="lineCov">         24 :     err_z = err_z - project(err_z + Σ.asDiagonal().inverse() * y,</span></a>
<a name="109"><span class="lineNum">     109 </span><span class="lineCov">         24 :                             p.D); // TODO: catastrophic cancellation?</span></a>
<a name="110"><span class="lineNum">     110 </span><span class="lineCov">         24 : }</span></a>
<a name="111"><span class="lineNum">     111 </span>            : </a>
<a name="112"><span class="lineNum">     112 </span>            : /**</a>
<a name="113"><span class="lineNum">     113 </span>            :  * Projected gradient step</a>
<a name="114"><span class="lineNum">     114 </span>            :  * @f[ \begin{aligned} </a>
<a name="115"><span class="lineNum">     115 </span>            :  * \hat{x}^k &amp;= T_{\gamma^k}\left(x^k\right) \\ </a>
<a name="116"><span class="lineNum">     116 </span>            :  * &amp;= \Pi_C\left(x^k - \gamma^k \nabla \psi(x^k)\right) \\ </a>
<a name="117"><span class="lineNum">     117 </span>            :  * p^k &amp;= \hat{x}^k - x^k \\ </a>
<a name="118"><span class="lineNum">     118 </span>            :  * \end{aligned} @f]</a>
<a name="119"><span class="lineNum">     119 </span>            :  */</a>
<a name="120"><span class="lineNum">     120 </span>            : inline auto</a>
<a name="121"><span class="lineNum">     121 </span><span class="lineCov">       1179 : projected_gradient_step(const Box &amp;C,     ///&lt; [in]  Set to project onto</span></a>
<a name="122"><span class="lineNum">     122 </span>            :                         real_t γ,         ///&lt; [in]  Step size</a>
<a name="123"><span class="lineNum">     123 </span>            :                         const vec &amp;x,     ///&lt; [in]  Decision variable @f$ x @f$</a>
<a name="124"><span class="lineNum">     124 </span>            :                         const vec &amp;grad_ψ ///&lt; [in]  @f$ \nabla \psi(x^k) @f$) {</a>
<a name="125"><span class="lineNum">     125 </span>            : ) {</a>
<a name="126"><span class="lineNum">     126 </span>            :     using binary_real_f = real_t (*)(real_t, real_t);</a>
<a name="127"><span class="lineNum">     127 </span><span class="lineCov">       3537 :     return (-γ * grad_ψ)</span></a>
<a name="128"><span class="lineNum">     128 </span><span class="lineCov">       1179 :         .binaryExpr(C.lowerbound - x, binary_real_f(std::fmax))</span></a>
<a name="129"><span class="lineNum">     129 </span><span class="lineCov">       1179 :         .binaryExpr(C.upperbound - x, binary_real_f(std::fmin));</span></a>
<a name="130"><span class="lineNum">     130 </span>            : }</a>
<a name="131"><span class="lineNum">     131 </span>            : </a>
<a name="132"><span class="lineNum">     132 </span><span class="lineCov">       1142 : inline void calc_x̂(const Problem &amp;prob, ///&lt; [in]  Problem description</span></a>
<a name="133"><span class="lineNum">     133 </span>            :                    real_t γ,            ///&lt; [in]  Step size</a>
<a name="134"><span class="lineNum">     134 </span>            :                    const vec &amp;x,        ///&lt; [in]  Decision variable @f$ x @f$</a>
<a name="135"><span class="lineNum">     135 </span>            :                    const vec &amp;grad_ψ,   ///&lt; [in]  @f$ \nabla \psi(x^k) @f$</a>
<a name="136"><span class="lineNum">     136 </span>            :                    vec &amp;x̂, ///&lt; [out] @f$ \hat{x}^k = T_{\gamma^k}(x^k) @f$</a>
<a name="137"><span class="lineNum">     137 </span>            :                    vec &amp;p  ///&lt; [out] @f$ \hat{x}^k - x^k @f$</a>
<a name="138"><span class="lineNum">     138 </span>            : ) {</a>
<a name="139"><span class="lineNum">     139 </span><span class="lineCov">       1142 :     p = projected_gradient_step(prob.C, γ, x, grad_ψ);</span></a>
<a name="140"><span class="lineNum">     140 </span><span class="lineCov">       1142 :     x̂ = x + p;</span></a>
<a name="141"><span class="lineNum">     141 </span><span class="lineCov">       1142 : }</span></a>
<a name="142"><span class="lineNum">     142 </span>            : </a>
<a name="143"><span class="lineNum">     143 </span>            : /// @f[ \left\| \gamma_k^{-1} (x^k - \hat x^k) + \nabla \psi(\hat x^k) -</a>
<a name="144"><span class="lineNum">     144 </span>            : /// \nabla \psi(x^k) \right\|_\infty @f]</a>
<a name="145"><span class="lineNum">     145 </span><span class="lineCov">        696 : inline real_t calc_error_stop_crit(</span></a>
<a name="146"><span class="lineNum">     146 </span>            :     const vec &amp;pₖ, ///&lt; [in]  Projected gradient step @f$ \hat x^k - x^k @f$</a>
<a name="147"><span class="lineNum">     147 </span>            :     real_t γ,      ///&lt; [in]  Step size</a>
<a name="148"><span class="lineNum">     148 </span>            :     const vec &amp;grad_̂ψₖ, ///&lt; [in]  Gradient in @f$ \hat x^k @f$</a>
<a name="149"><span class="lineNum">     149 </span>            :     const vec &amp;grad_ψₖ  ///&lt; [in]  Gradient in @f$ x^k @f$</a>
<a name="150"><span class="lineNum">     150 </span>            : ) {</a>
<a name="151"><span class="lineNum">     151 </span><span class="lineCov">        696 :     auto err = (1 / γ) * pₖ + (grad_ψₖ - grad_̂ψₖ);</span></a>
<a name="152"><span class="lineNum">     152 </span>            :     // These parentheses     ^^^               ^^^</a>
<a name="153"><span class="lineNum">     153 </span>            :     // are important to prevent catastrophic cancellation when the step is small</a>
<a name="154"><span class="lineNum">     154 </span><span class="lineCov">        696 :     auto ε = vec_util::norm_inf(err);</span></a>
<a name="155"><span class="lineNum">     155 </span><span class="lineCov">       1392 :     return ε;</span></a>
<a name="156"><span class="lineNum">     156 </span><span class="lineCov">        696 : }</span></a>
<a name="157"><span class="lineNum">     157 </span>            : </a>
<a name="158"><span class="lineNum">     158 </span>            : } // namespace pa::detail</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.15</a></td></tr>
  </table>
  <br>

</body>
</html>
